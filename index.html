<!DOCTYPE html>
<meta charset="UTF-8">

<html>
  <head>
    <style>
        body {
            background-color: black;
            color: white;
            font-family: "Arial";
        }
        #vcenter {
            top:50%;
            left:50%;
            height:300px;
            width:600px;
            position: absolute;
            margin: -150px 0 0 -300px;
        }
        #vcenter h1 {
            margin:auto;
            line-height:300px;
            vertical-align:middle;
            text-align: center;
            font-size: 180px;
        }

      .on {
        opacity: 1;
        transition: opacity 0.1s;
        -ms-transition: opacity 0.1s;
        -moz-transition: opacity 0.1s;
        -webkit-transition: opacity 0.1s;
      }
      .off {
        opacity: 0;
      }

    </style>
  </head>
  <body>
      <div id="vcenter">
          <h1 id="word">begin</h1>
      </div>
      <div id="pause-status">
      </div>
  </body>
  <script>

    var words = ["eat", "Ed", "add"];
    var log = {startTime: new Date().getTime(), trials: [], pauses: []};
    var interstimdur_ms = 500;
    if (window.location.hash.length > 3){
      words = window.location.hash.slice(1).split(",");
    }
    speechDetector(200, 150 /*ms*/, function(){requestNextTrial("mic");})

    var count = 0;
    var readyToAdvance = true;
    var currentWord = "";
    var isPaused = false;
    renderPauseStatus();
    
    window.addEventListener("keyup",handleKeyup)

    function requestNextTrial(whoCalledMe){
      if (!readyToAdvance) return;
      if (whoCalledMe === "mic" && isPaused) return;

      readyToAdvance = false;
      count++;
      currentWord = getNextWord();
      log.trials.push({
        t: new Date().getTime()-log.startTime,
        count: count,
        word: currentWord,
        source: whoCalledMe
      })
      document.getElementById("word").className  = "off";
      setTimeout(function(){
        document.getElementById("word").innerHTML = currentWord;
        document.getElementById("word").className = "on";
        readyToAdvance = true;
      }, interstimdur_ms);
    }

    function getNextWord(){
      if (count <= words.length) {	// loop through experiment word list
        return words[count-1]
      } else {                      // or pick random word
        return words[Math.floor((Math.random() * words.length))]
      }
    }
    
    function handleKeyup(e){
      if (e.code == "Space") {
        isPaused = !isPaused;
        renderPauseStatus();
        log.pauses.push({
            t: new Date().getTime()-log.startTime,
            status: isPaused
        })
      } else if (e.code == "ArrowRight") {
        requestNextTrial("keyboard")
      } else if (e.code == "KeyL") {
        displayLog();
      }
    }
    
    function renderPauseStatus(){
       document.getElementById("pause-status").innerHTML = isPaused ? "[ paused ]" : "";
    }
    
    function displayLog(){
       window.open('data:application/json;' + 'base64,'+btoa(JSON.stringify(log,null,2)));
    }

    function speechDetector(THRESHOLD, DURATION, onUtterance){

      navigator.getUserMedia = (
        navigator.getUserMedia ||
          navigator.webkitGetUserMedia ||
            navigator.mozGetUserMedia ||
              navigator.msGetUserMedia
      );

      var audioCtx = new AudioContext();
      var scriptNode = audioCtx.createScriptProcessor(4096, 1, 1);

      navigator.getUserMedia({audio:true}, success, function(e) {
        alert('Error capturing audio.');
      });

      var source = null;
      function success(e){
        source = audioCtx.createMediaStreamSource(e);
        source.connect(scriptNode);
        source.onended = function() {
          source.disconnect(scriptNode);
          scriptNode.disconnect(audioCtx.destination);
          console.log("Disconnected source");
        }
      }

      scriptNode.connect(audioCtx.destination);
      var onSince = -1, offSince = -1, lastCheck = -1, wasOn = false;

      // Give the node a function to process audio events
      scriptNode.onaudioprocess = function(audioProcessingEvent) {
        var inputBuffer = audioProcessingEvent.inputBuffer;
        var outputBuffer = audioProcessingEvent.outputBuffer;
        var data = inputBuffer.getChannelData(0);
        var sum = data.reduce(function(a,b){return a+Math.abs(b);}, 0);
        var now = new Date().getTime();
        if (sum > THRESHOLD){
          if (onSince < 0){
            onSince = now;
          }
          wasOn = false;
          offSince = -1;
          //console.log("ON", onSince, now, now - onSince)
        } else {
          //console.log("OFF", onSince, now)
          if ((onSince > 0) &&
              (now - onSince) > DURATION) {
                wasOn = true;
              }
              if (wasOn && (offSince > 0) && 
                  (now - offSince) > DURATION) {
                    console.log("Utterance Done", now)
                    onUtterance(now-onSince);
                    wasOn = false;
                  }

                  onSince = -1;
                  if (offSince < 0) {
                    offSince = now;
                  }
        }
        lastCheck = now;
      }
    }

  </script>
